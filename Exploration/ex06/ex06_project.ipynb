{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7278acc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.5\n",
      "2.6.0\n",
      "1.3.3\n",
      "1.2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /aiffel/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "import nltk\n",
    "import tensorflow\n",
    "import summa\n",
    "import pandas\n",
    "\n",
    "print(nltk.__version__)\n",
    "print(tensorflow.__version__)\n",
    "print(pandas.__version__)\n",
    "print(version('summa'))\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import urllib.request\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module = 'bs4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac92ef7c",
   "metadata": {},
   "source": [
    "## step 1. 데이터 수집"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5864e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/sunnysai12345/News_Summary/master/news_summary_more.csv\", filename=\"news_summary_more.csv\")\n",
    "data = pd.read_csv('news_summary_more.csv', encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1009f8d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59284</th>\n",
       "      <td>SL pacer fined for ball tampering in 2nd Test ...</td>\n",
       "      <td>Sri Lankan pacer Dasun Shanaka has been fined ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48445</th>\n",
       "      <td>Mughal emperor Aurangzeb was a terrorist: BJP MP</td>\n",
       "      <td>After the inauguration of a conference on Mugh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25813</th>\n",
       "      <td>BJP should name Mallya 'Make in India' ambassa...</td>\n",
       "      <td>Slamming BJP's Tribal Welfare Minister Jual Or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87445</th>\n",
       "      <td>Ranveer shoots despite injury on Padmavati set...</td>\n",
       "      <td>As per reports, Ranveer Singh hurt himself on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54537</th>\n",
       "      <td>New Sri Lanka cricket coach bans music during ...</td>\n",
       "      <td>Sri Lanka cricket coach Chandika Hathurusingha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5728</th>\n",
       "      <td>Amnesty takes down magazine cover 'sexualising...</td>\n",
       "      <td>Global human rights group Amnesty Internationa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33418</th>\n",
       "      <td>Who doesn't commit suicide: MP minister on far...</td>\n",
       "      <td>Speaking about farmer suicides, Madhya Pradesh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20984</th>\n",
       "      <td>Lost an elder brother: Tharoor condoles demise...</td>\n",
       "      <td>Condoling former UN Secretary-General Kofi Ann...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53921</th>\n",
       "      <td>Spider web-inspired implant may help control t...</td>\n",
       "      <td>Taking inspiration from the way dew drops stic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94925</th>\n",
       "      <td>New Malaysian law does not criminalise child m...</td>\n",
       "      <td>Malaysia has passed a law that offers stronger...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               headlines  \\\n",
       "59284  SL pacer fined for ball tampering in 2nd Test ...   \n",
       "48445   Mughal emperor Aurangzeb was a terrorist: BJP MP   \n",
       "25813  BJP should name Mallya 'Make in India' ambassa...   \n",
       "87445  Ranveer shoots despite injury on Padmavati set...   \n",
       "54537  New Sri Lanka cricket coach bans music during ...   \n",
       "5728   Amnesty takes down magazine cover 'sexualising...   \n",
       "33418  Who doesn't commit suicide: MP minister on far...   \n",
       "20984  Lost an elder brother: Tharoor condoles demise...   \n",
       "53921  Spider web-inspired implant may help control t...   \n",
       "94925  New Malaysian law does not criminalise child m...   \n",
       "\n",
       "                                                    text  \n",
       "59284  Sri Lankan pacer Dasun Shanaka has been fined ...  \n",
       "48445  After the inauguration of a conference on Mugh...  \n",
       "25813  Slamming BJP's Tribal Welfare Minister Jual Or...  \n",
       "87445  As per reports, Ranveer Singh hurt himself on ...  \n",
       "54537  Sri Lanka cricket coach Chandika Hathurusingha...  \n",
       "5728   Global human rights group Amnesty Internationa...  \n",
       "33418  Speaking about farmer suicides, Madhya Pradesh...  \n",
       "20984  Condoling former UN Secretary-General Kofi Ann...  \n",
       "53921  Taking inspiration from the way dew drops stic...  \n",
       "94925  Malaysia has passed a law that offers stronger...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "271ede07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98401"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0fe82e",
   "metadata": {},
   "source": [
    "- input sequence : text , output sequence : headlines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313a8d0f",
   "metadata": {},
   "source": [
    "## Step 2. 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594ca7c5",
   "metadata": {},
   "source": [
    "중복 데이터 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46349988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98360\n",
      "98280\n"
     ]
    }
   ],
   "source": [
    "print(data['text'].nunique())\n",
    "print(data['headlines'].nunique()) #두 데이터 모두 100개정도의 중복 존재"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67569bbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98360"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#text열 중복 제거\n",
    "data.drop_duplicates(['text'],inplace=True)\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a067cc48",
   "metadata": {},
   "source": [
    "결측치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2438267e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "headlines    0\n",
       "text         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3eb1e45",
   "metadata": {},
   "source": [
    "텍스트 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad47e727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정규화 사전의 수:  120\n"
     ]
    }
   ],
   "source": [
    "contractions = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}\n",
    "\n",
    "print(\"정규화 사전의 수: \", len(contractions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd0833c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불용어 개수 :  179\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print('불용어 개수 : ', len(stopwords.words('english')))\n",
    "print(stopwords.words('english')) #nltk 불용어 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106feb5c",
   "metadata": {},
   "source": [
    "### 전처리 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d59cae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence, remove_stopwords = True):\n",
    "    sentence = sentence.lower()\n",
    "    sentence = BeautifulSoup(sentence, 'lxml').text #html태그 제거\n",
    "    sentence = re.sub(r'\\([^)]*\\)','', sentence) #괄호로 닫힌 문자열\n",
    "    sentence = re.sub('\"','',sentence) #\"\"제거\n",
    "    sentence = ' '.join([contractions[t] if t in contractions else t for t in sentence.split(\" \")])\n",
    "    sentence = re.sub(r\"'s\\b'\",\"\",sentence)#소유격 제거 it's->it\n",
    "    sentence = re.sub(\"[^a-zA-Z]\",\" \",sentence)#영어이외 공백전환\n",
    "    sentence = re.sub('[m]{2,}','mm',sentence) #m이 3개 이상이면 2개로 변경 ummm->umm\n",
    "    \n",
    "    if remove_stopwords: #불용어 제거(Text경우)\n",
    "        tokens = ' '.join(word for word in sentence.split() if not word in stopwords.words('english') if len(word)>1)\n",
    "    else :\n",
    "        tokens = ' '.join(word for word in sentence.split() if len(word)>1)\n",
    "        \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61396c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['saurav kant alumnus upgrad iiit pg program machine learning artificial intelligence sr systems engineer infosys almost years work experience program upgrad degree career support helped transition data scientist tech mahindra salary hike upgrad online power learning powered lakh careers', 'kunal shah credit card bill payment platform cred gave users chance win free food swiggy one year pranav kaushik delhi techie bagged reward spending cred coins users get one cred coin per rupee bill paid used avail rewards brands like ixigo bookmyshow ubereats cult fit', 'new zealand defeated india wickets fourth odi hamilton thursday win first match five match odi series india lost international match rohit sharma captaincy consecutive victories dating back march match witnessed india getting seventh lowest total odi cricket history']\n"
     ]
    }
   ],
   "source": [
    "#text전처리\n",
    "clean_text = []\n",
    "\n",
    "for text in data['text']:\n",
    "    p_text = preprocess_sentence(text)\n",
    "    clean_text.append(p_text)\n",
    "    \n",
    "print(clean_text[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b51e3d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['saurav kant alumnus upgrad iiit pg program machine learning artificial intelligence sr systems engineer infosys almost years work experience program upgrad degree career support helped transition data scientist tech mahindra salary hike upgrad online power learning powered lakh careers', 'kunal shah credit card bill payment platform cred gave users chance win free food swiggy one year pranav kaushik delhi techie bagged reward spending cred coins users get one cred coin per rupee bill paid used avail rewards brands like ixigo bookmyshow ubereats cult fit', 'new zealand defeated india wickets fourth odi hamilton thursday win first match five match odi series india lost international match rohit sharma captaincy consecutive victories dating back march match witnessed india getting seventh lowest total odi cricket history']\n"
     ]
    }
   ],
   "source": [
    "#headlines전처리\n",
    "clean_headlines = []\n",
    "\n",
    "for text in data['headlines']:\n",
    "    p_line = preprocess_sentence(text,False)\n",
    "    clean_headlines.append(p_line)\n",
    "    \n",
    "print(clean_text[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1084574b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = clean_text\n",
    "data['headlines'] = clean_headlines\n",
    "\n",
    "#전처리 후 빈값->nan 처리\n",
    "data.replace('',np.nan,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "306d5eb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "headlines    0\n",
       "text         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum() #null값 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82b4f103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>upgrad learner switches to career in ml al wit...</td>\n",
       "      <td>saurav kant alumnus upgrad iiit pg program mac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>delhi techie wins free food from swiggy for on...</td>\n",
       "      <td>kunal shah credit card bill payment platform c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>new zealand end rohit sharma led india match w...</td>\n",
       "      <td>new zealand defeated india wickets fourth odi ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           headlines  \\\n",
       "0  upgrad learner switches to career in ml al wit...   \n",
       "1  delhi techie wins free food from swiggy for on...   \n",
       "2  new zealand end rohit sharma led india match w...   \n",
       "\n",
       "                                                text  \n",
       "0  saurav kant alumnus upgrad iiit pg program mac...  \n",
       "1  kunal shah credit card bill payment platform c...  \n",
       "2  new zealand defeated india wickets fourth odi ...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aacbee9",
   "metadata": {},
   "source": [
    "샘플의 길이 분포 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "de6ebe5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텍스트의 최소 길이 : 1\n",
      "텍스트의 최대 길이 : 60\n",
      "텍스트의 평균 길이 : 35.09968483123221\n",
      "헤드라인의 최소 길이 : 1\n",
      "헤드라인의 최대 길이 : 16\n",
      "헤드라인의 평균 길이 : 9.299532330215534\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 길이 분포 출력\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text_len = [len(s.split()) for s in data['text']]\n",
    "headlines_len = [len(s.split()) for s in data['headlines']]\n",
    "\n",
    "print('텍스트의 최소 길이 : {}'.format(np.min(text_len)))\n",
    "print('텍스트의 최대 길이 : {}'.format(np.max(text_len)))\n",
    "print('텍스트의 평균 길이 : {}'.format(np.mean(text_len)))\n",
    "print('헤드라인의 최소 길이 : {}'.format(np.min(headlines_len)))\n",
    "print('헤드라인의 최대 길이 : {}'.format(np.max(headlines_len)))\n",
    "print('헤드라인의 평균 길이 : {}'.format(np.mean(headlines_len)))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.boxplot(text_len)\n",
    "plt.title('Text')\n",
    "plt.subplot(1,2,2)\n",
    "plt.boxplot(headlines_len)\n",
    "plt.title('Headlines')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.title('Text')\n",
    "plt.hist(text_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()\n",
    "\n",
    "plt.title('Summary')\n",
    "plt.hist(headlines_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92dc0e05",
   "metadata": {},
   "source": [
    "- 분포를 통해, text의 최대 길이 50, headline의 최대 길이 16으로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e4bf0b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_max_len = 50\n",
    "headlines_max_len = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ecbe0a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 샘플의 비율 함수\n",
    "def below_threshold_len(max_len, nested_list):\n",
    "    cnt = 0\n",
    "    for s in nested_list:\n",
    "        if(len(s.split()) <= max_len):\n",
    "            cnt+=1\n",
    "    print('전체 샘플 중 길이가 %s 이하인 샘플의 비율 : %s' %(max_len, (cnt/len(nested_list))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f47bd03c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 중 길이가 50 이하인 샘플의 비율 : 0.9998576657177715\n",
      "전체 샘플 중 길이가 16 이하인 샘플의 비율 : 1.0\n"
     ]
    }
   ],
   "source": [
    "below_threshold_len(text_max_len, data['text'])\n",
    "below_threshold_len(headlines_max_len,  data['headlines'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e34757b",
   "metadata": {},
   "source": [
    "설정한 maxlen보다 작은 길이의 데이터는 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "31623856",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['text'].apply(lambda x : len(x.split()) <= text_max_len)]\n",
    "data = data[data['headlines'].apply(lambda x : len(x.split()) <= headlines_max_len)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5d44aac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98346"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b0a5f0",
   "metadata": {},
   "source": [
    "headlines 데이터에 시작 토큰과 종료 토큰 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d0c660d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "      <th>decoder_input</th>\n",
       "      <th>decoder_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>upgrad learner switches to career in ml al wit...</td>\n",
       "      <td>saurav kant alumnus upgrad iiit pg program mac...</td>\n",
       "      <td>sostoken upgrad learner switches to career in ...</td>\n",
       "      <td>upgrad learner switches to career in ml al wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>delhi techie wins free food from swiggy for on...</td>\n",
       "      <td>kunal shah credit card bill payment platform c...</td>\n",
       "      <td>sostoken delhi techie wins free food from swig...</td>\n",
       "      <td>delhi techie wins free food from swiggy for on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>new zealand end rohit sharma led india match w...</td>\n",
       "      <td>new zealand defeated india wickets fourth odi ...</td>\n",
       "      <td>sostoken new zealand end rohit sharma led indi...</td>\n",
       "      <td>new zealand end rohit sharma led india match w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aegon life iterm insurance plan helps customer...</td>\n",
       "      <td>aegon life iterm insurance plan customers enjo...</td>\n",
       "      <td>sostoken aegon life iterm insurance plan helps...</td>\n",
       "      <td>aegon life iterm insurance plan helps customer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>have known hirani for yrs what if metoo claims...</td>\n",
       "      <td>speaking sexual harassment allegations rajkuma...</td>\n",
       "      <td>sostoken have known hirani for yrs what if met...</td>\n",
       "      <td>have known hirani for yrs what if metoo claims...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           headlines  \\\n",
       "0  upgrad learner switches to career in ml al wit...   \n",
       "1  delhi techie wins free food from swiggy for on...   \n",
       "2  new zealand end rohit sharma led india match w...   \n",
       "3  aegon life iterm insurance plan helps customer...   \n",
       "4  have known hirani for yrs what if metoo claims...   \n",
       "\n",
       "                                                text  \\\n",
       "0  saurav kant alumnus upgrad iiit pg program mac...   \n",
       "1  kunal shah credit card bill payment platform c...   \n",
       "2  new zealand defeated india wickets fourth odi ...   \n",
       "3  aegon life iterm insurance plan customers enjo...   \n",
       "4  speaking sexual harassment allegations rajkuma...   \n",
       "\n",
       "                                       decoder_input  \\\n",
       "0  sostoken upgrad learner switches to career in ...   \n",
       "1  sostoken delhi techie wins free food from swig...   \n",
       "2  sostoken new zealand end rohit sharma led indi...   \n",
       "3  sostoken aegon life iterm insurance plan helps...   \n",
       "4  sostoken have known hirani for yrs what if met...   \n",
       "\n",
       "                                      decoder_target  \n",
       "0  upgrad learner switches to career in ml al wit...  \n",
       "1  delhi techie wins free food from swiggy for on...  \n",
       "2  new zealand end rohit sharma led india match w...  \n",
       "3  aegon life iterm insurance plan helps customer...  \n",
       "4  have known hirani for yrs what if metoo claims...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['decoder_input'] = data['headlines'].apply(lambda x : 'sostoken '+ x)\n",
    "data['decoder_target'] = data['headlines'].apply(lambda x : x + ' eostoken')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c606f4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#numpy로 다시 저장\n",
    "encoder_input = np.array(data['text']) # 인코더의 입력\n",
    "decoder_input = np.array(data['decoder_input']) # 디코더의 입력\n",
    "decoder_target = np.array(data['decoder_target']) # 디코더의 레이블"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff3a443",
   "metadata": {},
   "source": [
    "훈련/테스트 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "94987c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[36012 89662 12863 ...  6753 70545 19522]\n"
     ]
    }
   ],
   "source": [
    "#enocder_input과 크기, 형태가 같은 순서가 섞인 정수 시퀀스\n",
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "11694a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정수 시퀀스를 이용해 다시 데이터의 샘플 순서를 정의\n",
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "288b44e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터의 수 : 19669\n"
     ]
    }
   ],
   "source": [
    "#데이터의 20%는 테스트 데이터로\n",
    "n_of_val = int(len(encoder_input)*0.2)\n",
    "print('테스트 데이터의 수 :', n_of_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2fc04df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 개수 : 78677\n",
      "훈련 레이블의 개수 : 78677\n",
      "테스트 데이터의 개수 : 19669\n",
      "테스트 레이블의 개수 : 19669\n"
     ]
    }
   ],
   "source": [
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :', len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :', len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :', len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151b3af1",
   "metadata": {},
   "source": [
    "### 단어집합 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261046d8",
   "metadata": {},
   "source": [
    "- encoder 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "29de38da",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_tokenizer = Tokenizer() #토크나이저 정의\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 입력된 데이터로부터 단어 집합 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "49dc891d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 69632\n",
      "등장 빈도가 6번 이하인 희귀 단어의 수: 47448\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 22184\n",
      "단어 집합에서 희귀 단어의 비율: 68.14108455882352\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 3.4826367806328773\n"
     ]
    }
   ],
   "source": [
    "threshold = 7\n",
    "total_cnt = len(src_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in src_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6041d70",
   "metadata": {},
   "source": [
    "- 희귀단어를 제외한 단어 집합의 크기가 22184개인 것을 감안해 20000개로 제한"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7f677b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab = 20000 #입력데이터의 단어 집합 제한 개수\n",
    "src_tokenizer = Tokenizer(num_words=src_vocab) # 단어 집합의 크기를 20000으로 제한\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 단어 집합 재생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e554520e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3284, 390, 525, 264, 4292, 689, 576, 438, 699, 2659, 1477, 9306, 7575, 98, 4623, 763, 401, 4293, 3674, 466, 7468, 3, 13, 5486, 1, 891, 6052, 1477, 4196, 2639], [1085, 498, 1015, 1807, 107, 2425, 465, 556, 923, 2017, 1, 605, 1087, 2141, 2994, 4065, 611, 5080, 1442, 9684, 13363, 19503, 1206, 11261, 2503, 12569, 14770, 556, 10066, 498, 889, 498, 6182, 7469, 5872, 11570, 3191, 39]]\n"
     ]
    }
   ],
   "source": [
    "#정수 인코딩\n",
    "encoder_input_train = src_tokenizer.texts_to_sequences(encoder_input_train)\n",
    "encoder_input_test = src_tokenizer.texts_to_sequences(encoder_input_test)\n",
    "\n",
    "print(encoder_input_train[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5a7ec8",
   "metadata": {},
   "source": [
    "- decoder 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e6baf804",
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_tokenizer = Tokenizer()\n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f7163866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 30104\n",
      "등장 빈도가 5번 이하인 희귀 단어의 수: 19722\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 10382\n",
      "단어 집합에서 희귀 단어의 비율: 65.51288865267074\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 4.665977366610568\n"
     ]
    }
   ],
   "source": [
    "threshold = 6\n",
    "total_cnt = len(tar_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in tar_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adaef63",
   "metadata": {},
   "source": [
    "- 회귀 단어의 차지 비율이 4%이고 이를 제외할 경우의 단어 집합의 크기가 10382인 것을 토대로 디코더 단어 집합의 크기를 10000으로 제한"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1ebf7c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input\n",
      "input  [[1, 555, 921, 2007, 1664, 3048, 5, 6865, 2916, 1954], [1, 24, 497, 1263, 5201, 4, 236, 5423, 6536, 259], [1, 126, 6, 403, 2789, 5, 2136, 930, 361, 47, 4], [1, 4698, 1050, 194, 64, 26, 2856, 3488, 151, 101, 575, 129], [1, 18, 3117, 1411, 156, 1241, 3, 6537, 3326, 9, 1514, 688]]\n",
      "target\n",
      "decoder  [[555, 921, 2007, 1664, 3048, 5, 6865, 2916, 1954, 2], [24, 497, 1263, 5201, 4, 236, 5423, 6536, 259, 2], [126, 6, 403, 2789, 5, 2136, 930, 361, 47, 4, 2], [4698, 1050, 194, 64, 26, 2856, 3488, 151, 101, 575, 129, 2], [18, 3117, 1411, 156, 1241, 3, 6537, 3326, 9, 1514, 688, 2]]\n"
     ]
    }
   ],
   "source": [
    "tar_vocab = 10000 #target문장들의 단어 집합 제한 개수\n",
    "tar_tokenizer = Tokenizer(num_words=tar_vocab)\n",
    "tar_tokenizer.fit_on_texts(decoder_input_train) #단어 집합 재생성\n",
    "tar_tokenizer.fit_on_texts(decoder_target_train) #단어 집합 재생성\n",
    "\n",
    "# 정수인코딩\n",
    "decoder_input_train = tar_tokenizer.texts_to_sequences(decoder_input_train)\n",
    "decoder_target_train = tar_tokenizer.texts_to_sequences(decoder_target_train)\n",
    "decoder_input_test = tar_tokenizer.texts_to_sequences(decoder_input_test)\n",
    "decoder_target_test = tar_tokenizer.texts_to_sequences(decoder_target_test)\n",
    "\n",
    "# 잘 변환되었는지 확인\n",
    "print('input')\n",
    "print('input ',decoder_input_train[:5])\n",
    "print('target')\n",
    "print('decoder ',decoder_target_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ce5774e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삭제할 훈련 데이터의 개수 : 0\n",
      "삭제할 테스트 데이터의 개수 : 0\n",
      "훈련 데이터의 개수 : 78677\n",
      "훈련 레이블의 개수 : 78677\n",
      "테스트 데이터의 개수 : 19669\n",
      "테스트 레이블의 개수 : 19669\n"
     ]
    }
   ],
   "source": [
    "#headlines의 길이가 0이 된 샘플 삭제\n",
    "#sostoken, eostoken이 존재하므로 길이가 1인 열을 삭제\n",
    "\n",
    "drop_train = [index for index, sentence in enumerate(decoder_input_train) if len(sentence) == 1]\n",
    "drop_test = [index for index, sentence in enumerate(decoder_input_test) if len(sentence) == 1]\n",
    "\n",
    "print('삭제할 훈련 데이터의 개수 :', len(drop_train))\n",
    "print('삭제할 테스트 데이터의 개수 :', len(drop_test))\n",
    "\n",
    "encoder_input_train = [sentence for index, sentence in enumerate(encoder_input_train) if index not in drop_train]\n",
    "decoder_input_train = [sentence for index, sentence in enumerate(decoder_input_train) if index not in drop_train]\n",
    "decoder_target_train = [sentence for index, sentence in enumerate(decoder_target_train) if index not in drop_train]\n",
    "\n",
    "encoder_input_test = [sentence for index, sentence in enumerate(encoder_input_test) if index not in drop_test]\n",
    "decoder_input_test = [sentence for index, sentence in enumerate(decoder_input_test) if index not in drop_test]\n",
    "decoder_target_test = [sentence for index, sentence in enumerate(decoder_target_test) if index not in drop_test]\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :', len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :', len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :', len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74871baf",
   "metadata": {},
   "source": [
    "패딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "60cca474",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_train = pad_sequences(encoder_input_train, maxlen=text_max_len, padding='post')\n",
    "encoder_input_test = pad_sequences(encoder_input_test, maxlen=text_max_len, padding='post')\n",
    "\n",
    "decoder_input_train = pad_sequences(decoder_input_train, maxlen=headlines_max_len, padding='post')\n",
    "decoder_input_test = pad_sequences(decoder_input_test, maxlen=headlines_max_len, padding='post')\n",
    "\n",
    "decoder_target_train = pad_sequences(decoder_target_train, maxlen=headlines_max_len, padding='post')\n",
    "decoder_target_test = pad_sequences(decoder_target_test, maxlen=headlines_max_len, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316b9ea7",
   "metadata": {},
   "source": [
    "## Step 3. 어텐션 매커니즘 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b2b4ea",
   "metadata": {},
   "source": [
    "모델 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b5164fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "#함수형 API\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "# 인코더 설계 시작\n",
    "embedding_dim = 128\n",
    "hidden_size = 256\n",
    "\n",
    "# 인코더\n",
    "encoder_inputs = Input(shape=(text_max_len,))\n",
    "\n",
    "# 인코더의 임베딩 층\n",
    "enc_emb = Embedding(src_vocab, embedding_dim)(encoder_inputs)\n",
    "\n",
    "# 인코더의 LSTM 1\n",
    "encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4, recurrent_dropout = 0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "# 인코더의 LSTM 2\n",
    "encoder_lstm2 = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "# 인코더의 LSTM 3\n",
    "encoder_lstm3 = LSTM(hidden_size, return_state=True, return_sequences=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fdd123f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "# 디코더 설계\n",
    "decoder_inputs = Input(shape=(None,))#가변적이기때문에 None ???\n",
    "\n",
    "# 디코더의 임베딩 층\n",
    "dec_emb_layer = Embedding(tar_vocab, embedding_dim)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 디코더의 LSTM\n",
    "decoder_lstm = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=[state_h, state_c])\n",
    "# initial_state = [state_h,state_c] : 인코더에서 전달된 contextvecotr을 초기상태로 설정한 부분\n",
    "\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "464314f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 50, 128)      2560000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 50, 256), (N 394240      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 50, 256), (N 525312      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 128)    1280000     input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 50, 256), (N 525312      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   [(None, None, 256),  394240      embedding_2[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 10000)  2570000     lstm_4[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 8,249,104\n",
      "Trainable params: 8,249,104\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d68ec85",
   "metadata": {},
   "source": [
    "- 어텐션 층 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b16bf81f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 50, 128)      2560000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 50, 256), (N 394240      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 50, 256), (N 525312      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 128)    1280000     input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 50, 256), (N 525312      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   [(None, None, 256),  394240      embedding_2[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AdditiveAttent (None, None, 256)    256         lstm_4[0][0]                     \n",
      "                                                                 lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 512)    0           lstm_4[0][0]                     \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 10000)  5130000     concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 10,809,360\n",
      "Trainable params: 10,809,360\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import AdditiveAttention\n",
    "\n",
    "# 어텐션 층(어텐션 함수)\n",
    "attn_layer = AdditiveAttention(name='attention_layer')\n",
    "\n",
    "# 인코더와 디코더의 모든 time step의 hidden state를 어텐션 층에 전달하고 결과를 리턴\n",
    "attn_out = attn_layer([decoder_outputs, encoder_outputs])\n",
    "\n",
    "\n",
    "# 어텐션의 결과와 디코더의 hidden state들을 연결\n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_concat_input)\n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605b35ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "308/308 [==============================] - 232s 725ms/step - loss: 4.2899 - val_loss: 3.9389\n",
      "Epoch 2/50\n",
      "308/308 [==============================] - 222s 722ms/step - loss: 3.8021 - val_loss: 3.6363\n",
      "Epoch 3/50\n",
      "308/308 [==============================] - 220s 714ms/step - loss: 3.5539 - val_loss: 3.4348\n",
      "Epoch 4/50\n",
      "308/308 [==============================] - 221s 717ms/step - loss: 3.3621 - val_loss: 3.3125\n",
      "Epoch 5/50\n",
      "308/308 [==============================] - 221s 718ms/step - loss: 3.2061 - val_loss: 3.1812\n",
      "Epoch 6/50\n",
      "308/308 [==============================] - 219s 711ms/step - loss: 3.0779 - val_loss: 3.0980\n",
      "Epoch 7/50\n",
      "308/308 [==============================] - 220s 715ms/step - loss: 2.9700 - val_loss: 3.0327\n",
      "Epoch 8/50\n",
      "308/308 [==============================] - 219s 712ms/step - loss: 2.8785 - val_loss: 2.9788\n",
      "Epoch 9/50\n",
      "308/308 [==============================] - 220s 716ms/step - loss: 2.7985 - val_loss: 2.9351\n",
      "Epoch 10/50\n",
      "308/308 [==============================] - 223s 723ms/step - loss: 2.7274 - val_loss: 2.8962\n",
      "Epoch 11/50\n",
      "308/308 [==============================] - 220s 715ms/step - loss: 2.6652 - val_loss: 2.8701\n",
      "Epoch 12/50\n",
      "308/308 [==============================] - 219s 711ms/step - loss: 2.6097 - val_loss: 2.8407\n",
      "Epoch 13/50\n",
      "308/308 [==============================] - 219s 711ms/step - loss: 2.5593 - val_loss: 2.8176\n",
      "Epoch 14/50\n",
      "308/308 [==============================] - 219s 713ms/step - loss: 2.5113 - val_loss: 2.8012\n",
      "Epoch 15/50\n",
      "308/308 [==============================] - 220s 714ms/step - loss: 2.4678 - val_loss: 2.7874\n",
      "Epoch 16/50\n",
      "308/308 [==============================] - 219s 711ms/step - loss: 2.4264 - val_loss: 2.7657\n",
      "Epoch 17/50\n",
      "308/308 [==============================] - 224s 728ms/step - loss: 2.3882 - val_loss: 2.7525\n",
      "Epoch 18/50\n",
      "308/308 [==============================] - 220s 713ms/step - loss: 2.3544 - val_loss: 2.7422\n",
      "Epoch 19/50\n",
      "308/308 [==============================] - 220s 715ms/step - loss: 2.3220 - val_loss: 2.7424\n",
      "Epoch 20/50\n",
      "308/308 [==============================] - 220s 713ms/step - loss: 2.2890 - val_loss: 2.7248\n",
      "Epoch 21/50\n",
      "308/308 [==============================] - 219s 711ms/step - loss: 2.2590 - val_loss: 2.7226\n",
      "Epoch 22/50\n",
      "308/308 [==============================] - 219s 712ms/step - loss: 2.2333 - val_loss: 2.7157\n",
      "Epoch 23/50\n",
      "308/308 [==============================] - 219s 710ms/step - loss: 2.2069 - val_loss: 2.7070\n",
      "Epoch 24/50\n",
      "308/308 [==============================] - 218s 708ms/step - loss: 2.1805 - val_loss: 2.7094\n",
      "Epoch 25/50\n",
      "308/308 [==============================] - 219s 711ms/step - loss: 2.1581 - val_loss: 2.7005\n",
      "Epoch 26/50\n",
      "308/308 [==============================] - 219s 711ms/step - loss: 2.1344 - val_loss: 2.6966\n",
      "Epoch 27/50\n",
      "308/308 [==============================] - 219s 710ms/step - loss: 2.1123 - val_loss: 2.6926\n",
      "Epoch 28/50\n",
      "158/308 [==============>...............] - ETA: 1:43 - loss: 2.0648"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
    "es = EarlyStopping(monitor='val_loss', patience=2, verbose=1)\n",
    "history = model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n",
    "          validation_data=([encoder_input_test, decoder_input_test], decoder_target_test), \\\n",
    "          batch_size=256, callbacks=[es], epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8a82b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0febcc80",
   "metadata": {},
   "source": [
    "텍스트 데이터 형태로 출력하기 위해선 복원하는 과정이 필요하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0ce933",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_index_to_word = src_tokenizer.index_word # 원문 단어 집합에서 정수 -> 단어를 얻음\n",
    "tar_word_to_index = tar_tokenizer.word_index # 요약 단어 집합에서 단어 -> 정수를 얻음\n",
    "tar_index_to_word = tar_tokenizer.index_word # 요약 단어 집합에서 정수 -> 단어를 얻음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392b2447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 설계\n",
    "encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "# 이전 시점의 상태들을 저장하는 텐서\n",
    "decoder_state_input_h = Input(shape=(hidden_size,))\n",
    "decoder_state_input_c = Input(shape=(hidden_size,))\n",
    "\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용. 이는 뒤의 함수 decode_sequence()에 구현\n",
    "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태인 state_h와 state_c를 버리지 않음.\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513a4b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#어텐션 메커니즘을 사용하는 출력층 설계\n",
    "# 어텐션 함수\n",
    "decoder_hidden_state_input = Input(shape=(text_max_len, hidden_size))\n",
    "attn_out_inf = attn_layer([decoder_outputs2, decoder_hidden_state_input])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_outputs2 = decoder_softmax_layer(decoder_inf_concat)\n",
    "\n",
    "# 최종 디코더 모델\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33b43a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "\n",
    "     # <SOS>에 해당하는 토큰 생성\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = tar_word_to_index['sostoken']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition: # stop_condition이 True가 될 때까지 루프 반복\n",
    "\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = tar_index_to_word[sampled_token_index]\n",
    "\n",
    "        if (sampled_token!='eostoken'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "        #  <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_token == 'eostoken'  or len(decoded_sentence.split()) >= (summary_max_len-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 길이가 1인 타겟 시퀀스를 업데이트\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # 상태를 업데이트 합니다.\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4b6e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2text(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if (i!=0):\n",
    "            temp = temp + src_index_to_word[i]+' '\n",
    "    return temp\n",
    "\n",
    "# 요약문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2summary(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if i!=0 and i!=tar_word_to_index['sostoken'] and i!=tar_word_to_index['eostoken']:\n",
    "            temp = temp + src_index_to_word[i]+' '\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cfd7a9",
   "metadata": {},
   "source": [
    "## Step 4. 실제 결과와 요약문 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe88c6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50, 60):\n",
    "    print(\"원문 :\", seq2text(encoder_input_test[i]))\n",
    "    print(\"실제 요약 :\", seq2summary(decoder_input_test[i]))\n",
    "    print(\"예측 요약 :\", decode_sequence(encoder_input_test[i].reshape(1, text_max_len)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7fcddb",
   "metadata": {},
   "source": [
    "## Step 5. Summa을 이용해서 추출적 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1338612",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from summa.summarizer import summarize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75b90a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/sunnysai12345/News_Summary/master/news_summary_more.csv\", filename=\"news_summary_more.csv\")\n",
    "data = pd.read_csv('news_summary_more.csv', encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60ffba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, (head, text) in enumerate(zip(data['headlines'], data['text'])):\n",
    "    if idx == 10:\n",
    "        break\n",
    "    print(\"원문 :\", text)\n",
    "    print(\"실제 요약 :\", head)\n",
    "    print(\"추출적 요약 :\", summarize(text, ratio=0.40))\n",
    "    # print(\"예측 요약 :\", decode_sequence(encoder_input_test[i].reshape(1, text_max_len)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f210c06",
   "metadata": {},
   "source": [
    "## 회고"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acab0b15",
   "metadata": {},
   "source": [
    "- 어려웠던 점 : 아직 내 스스로 seq2seq모델의 인코더디코더의 내부 과정을 정확하게 이해하지 못한 것 같다. 이 부분을 정리하고 코드의 흐름을 따라가면 더 잘 코드를 습득할 수 있을 것 같다.\n",
    "- 아쉬웠던 점 : earlystopping을 사용했음에도 모델 훈련에 오랜 시간이 걸려 주어진 시간내에 코드를 돌려보지 못했다.\n",
    "- 배운 점 : 단어들은 ㅇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834ef1ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
